{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistema de ML Multi-Módulo\n",
    "Seleccione el módulo a ejecutar:\n",
    "1. Predicción de Series Temporales (Ventas)\n",
    "2. Clasificación de Imágenes (MNIST)\n",
    "3. Análisis de Sentimientos\n",
    "4. Generación de Contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas numpy matplotlib seaborn scikit-learn tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Conv2D, MaxPooling2D, Flatten, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import math\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import io\n",
    "\n",
    "# Configurar semilla para reproducibilidad\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Función para elegir qué módulo ejecutar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejecutar_modulo(opcion):\n",
    "    if opcion == 1:\n",
    "        print(\"\\n=== EJECUTANDO MÓDULO 1: PREDICCIÓN DE SERIES TEMPORALES ===\")\n",
    "        modulo_prediccion_ventas()\n",
    "    elif opcion == 2:\n",
    "        print(\"\\n=== EJECUTANDO MÓDULO 2: CLASIFICACIÓN DE IMÁGENES ===\")\n",
    "        modulo_clasificacion_imagenes()\n",
    "    elif opcion == 3:\n",
    "        print(\"\\n=== EJECUTANDO MÓDULO 3: ANÁLISIS DE SENTIMIENTOS ===\")\n",
    "        modulo_analisis_sentimientos()\n",
    "    elif opcion == 4:\n",
    "        print(\"\\n=== EJECUTANDO MÓDULO 4: GENERACIÓN DE CONTENIDO ===\")\n",
    "        modulo_generacion_contenido()\n",
    "    else:\n",
    "        print(\"Opción no válida\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Módulo 1: Predicción de Series Temporales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modulo_prediccion_ventas():\n",
    "    print(\"=== GENERANDO DATASET DE VENTAS ===\")\n",
    "    # Generar fechas para un año (2023)\n",
    "    start_date = datetime(2023, 1, 1)\n",
    "    end_date = datetime(2023, 12, 31)\n",
    "    dates = [start_date + timedelta(days=i) for i in range((end_date - start_date).days + 1)]\n",
    "    \n",
    "    # Crear diccionario para días festivos en España (simplificado)\n",
    "    holidays = {\n",
    "        '2023-01-01': 'Año Nuevo',\n",
    "        '2023-01-06': 'Reyes Magos',\n",
    "        '2023-04-07': 'Viernes Santo',\n",
    "        '2023-05-01': 'Día del Trabajo',\n",
    "        '2023-08-15': 'Asunción',\n",
    "        '2023-10-12': 'Día de la Hispanidad',\n",
    "        '2023-11-01': 'Todos los Santos',\n",
    "        '2023-12-06': 'Día de la Constitución',\n",
    "        '2023-12-08': 'Inmaculada Concepción',\n",
    "        '2023-12-25': 'Navidad'\n",
    "    }\n",
    "    \n",
    "    # Función para determinar la temporada\n",
    "    def get_season(date):\n",
    "        month = date.month\n",
    "        if month in [12, 1, 2]:\n",
    "            return 'Invierno'\n",
    "        elif month in [3, 4, 5]:\n",
    "            return 'Primavera'\n",
    "        elif month in [6, 7, 8]:\n",
    "            return 'Verano'\n",
    "        else:\n",
    "            return 'Otoño'\n",
    "    \n",
    "    # Generar datos para cada día\n",
    "    data = []\n",
    "    for date in dates:\n",
    "        day_of_week = date.weekday()  # 0-6 (lunes-domingo)\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Determinar si es festivo\n",
    "        is_holiday = 1 if date_str in holidays else 0\n",
    "        \n",
    "        # Temporada\n",
    "        season = get_season(date)\n",
    "        \n",
    "        # Temperatura (simulada según temporada)\n",
    "        if season == 'Invierno':\n",
    "            temp = np.random.normal(10, 5)\n",
    "        elif season == 'Primavera':\n",
    "            temp = np.random.normal(18, 5)\n",
    "        elif season == 'Verano':\n",
    "            temp = np.random.normal(28, 5)\n",
    "        else:  # Otoño\n",
    "            temp = np.random.normal(15, 5)\n",
    "        \n",
    "        # Lluvia (probabilidad varía según temporada)\n",
    "        if season == 'Invierno' or season == 'Otoño':\n",
    "            rain = np.random.choice([0, 1], p=[0.6, 0.4])\n",
    "        else:\n",
    "            rain = np.random.choice([0, 1], p=[0.8, 0.2])\n",
    "        \n",
    "        # Promociones (aleatorias con mayor probabilidad en ciertos meses)\n",
    "        if date.month in [1, 7]:  # Rebajas\n",
    "            promo = np.random.choice([0, 1], p=[0.3, 0.7])\n",
    "        else:\n",
    "            promo = np.random.choice([0, 1], p=[0.8, 0.2])\n",
    "        \n",
    "        # Base de ventas según día de la semana\n",
    "        if day_of_week < 5:  # Lunes a viernes\n",
    "            base_sales = np.random.normal(1000, 200)\n",
    "        else:  # Fin de semana\n",
    "            base_sales = np.random.normal(1500, 300)\n",
    "        \n",
    "        # Modificadores\n",
    "        if is_holiday:\n",
    "            base_sales *= np.random.uniform(0.8, 1.2)  # Efecto variable de festivos\n",
    "        \n",
    "        if promo:\n",
    "            base_sales *= np.random.uniform(1.2, 1.6)  # Efecto de promociones\n",
    "        \n",
    "        # Efecto de la temperatura (las temperaturas moderadas favorecen las ventas)\n",
    "        temp_effect = -0.001 * (temp - 22) ** 2 + 1\n",
    "        base_sales *= temp_effect\n",
    "        \n",
    "        # Efecto de la lluvia (reduce ventas)\n",
    "        if rain:\n",
    "            base_sales *= np.random.uniform(0.8, 0.95)\n",
    "        \n",
    "        # Tendencia anual (ligero crecimiento)\n",
    "        day_of_year = date.timetuple().tm_yday\n",
    "        trend = 1 + (day_of_year / 365) * 0.05\n",
    "        base_sales *= trend\n",
    "        \n",
    "        # Picos estacionales\n",
    "        if date.month == 12:  # Navidad\n",
    "            base_sales *= np.random.uniform(1.3, 1.8)\n",
    "        elif date.month == 11 and date.day > 25:  # Black Friday\n",
    "            base_sales *= np.random.uniform(1.4, 2.0)\n",
    "        \n",
    "        # Añadir ruido final\n",
    "        sales = max(0, int(base_sales * np.random.normal(1, 0.05)))\n",
    "        \n",
    "        data.append({\n",
    "            'fecha': date_str,\n",
    "            'dia_semana': day_of_week,\n",
    "            'festivo': is_holiday,\n",
    "            'temporada': season,\n",
    "            'temperatura': round(temp, 1),\n",
    "            'lluvia': rain,\n",
    "            'promocion': promo,\n",
    "            'ventas': sales\n",
    "        })\n",
    "\n",
    "    # Crear DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # One-hot encoding para temporada\n",
    "    season_dummies = pd.get_dummies(df['temporada'], prefix='temporada')\n",
    "    df = pd.concat([df, season_dummies], axis=1)\n",
    "\n",
    "    # Convertir día de la semana a categoría cíclica usando seno y coseno\n",
    "    df['dia_semana_sin'] = np.sin(2 * np.pi * df['dia_semana'] / 7)\n",
    "    df['dia_semana_cos'] = np.cos(2 * np.pi * df['dia_semana'] / 7)\n",
    "\n",
    "    # Guardar el DataFrame a un archivo CSV\n",
    "    df.to_csv('ventas_tienda_diarias.csv', index=False)\n",
    "\n",
    "    print(f\"\\nDataset creado y guardado como 'ventas_tienda_diarias.csv'\")\n",
    "    print(f\"Tamaño del dataset: {len(df)} registros\")\n",
    "\n",
    "    # Mostrar algunas estadísticas básicas\n",
    "    print(\"\\nEstadísticas de ventas:\")\n",
    "    print(df['ventas'].describe())\n",
    "\n",
    "    print(\"\\n=== ENTRENANDO MODELO DE RED NEURONAL ===\")\n",
    "\n",
    "    # Preparar los datos para la red neuronal\n",
    "    # Seleccionar características y objetivo\n",
    "    X = df[['dia_semana_sin', 'dia_semana_cos', 'festivo', 'temperatura',\n",
    "            'lluvia', 'promocion', 'temporada_Invierno', 'temporada_Otoño',\n",
    "            'temporada_Primavera', 'temporada_Verano']]\n",
    "    y = df['ventas']\n",
    "\n",
    "    # Normalizar los datos\n",
    "    scaler_X = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "\n",
    "    X_scaled = scaler_X.fit_transform(X)\n",
    "    y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))\n",
    "\n",
    "    # Dividir en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Construir el modelo de red neuronal\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1)  # Capa de salida para la regresión\n",
    "    ])\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "    # Configurar early stopping para evitar sobreajuste\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=20,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,  # Reducido para que sea más rápido\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    train_loss, train_mae = model.evaluate(X_train, y_train, verbose=0)\n",
    "    test_loss, test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    print(f'\\nPérdida en entrenamiento: {train_loss:.4f}')\n",
    "    print(f'MAE en entrenamiento: {train_mae:.4f}')\n",
    "    print(f'Pérdida en prueba: {test_loss:.4f}')\n",
    "    print(f'MAE en prueba: {test_mae:.4f}')\n",
    "\n",
    "    # Hacer predicciones\n",
    "    y_pred_scaled = model.predict(X_test)\n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "    y_test_actual = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "    # Calcular métricas de error en valores originales (no escalados)\n",
    "    mae = mean_absolute_error(y_test_actual, y_pred)\n",
    "    rmse = math.sqrt(mean_squared_error(y_test_actual, y_pred))\n",
    "    r2 = r2_score(y_test_actual, y_pred)\n",
    "\n",
    "    print(f'\\nMAE (valores originales): {mae:.2f}')\n",
    "    print(f'RMSE (valores originales): {rmse:.2f}')\n",
    "    print(f'R²: {r2:.4f}')\n",
    "\n",
    "    # Guardar el modelo entrenado\n",
    "    model.save('modelo_ventas_tienda.h5')\n",
    "    print(\"\\nModelo guardado como 'modelo_ventas_tienda.h5'\")\n",
    "\n",
    "    # Función para predecir ventas con nuevos datos\n",
    "    def predict_sales(dia_semana, festivo, temperatura, lluvia, promocion, temporada):\n",
    "        \"\"\"Predecir ventas con nuevos datos\"\"\"\n",
    "        # Convertir día de la semana a valores cíclicos\n",
    "        dia_semana_sin = np.sin(2 * np.pi * dia_semana / 7)\n",
    "        dia_semana_cos = np.cos(2 * np.pi * dia_semana / 7)\n",
    "       \n",
    "        # Preparar temporada (one-hot encoding)\n",
    "        temp_invierno = 1 if temporada == 'Invierno' else 0\n",
    "        temp_otono = 1 if temporada == 'Otoño' else 0\n",
    "        temp_primavera = 1 if temporada == 'Primavera' else 0\n",
    "        temp_verano = 1 if temporada == 'Verano' else 0\n",
    "       \n",
    "        # Crear array de entrada\n",
    "        X_new = np.array([[dia_semana_sin, dia_semana_cos, festivo, temperatura,\n",
    "                          lluvia, promocion, temp_invierno, temp_otono,\n",
    "                          temp_primavera, temp_verano]])\n",
    "        \n",
    "        # Normalizar\n",
    "        X_new_scaled = scaler_X.transform(X_new)\n",
    "        \n",
    "        # Predecir\n",
    "        y_new_scaled = model.predict(X_new_scaled)\n",
    "        \n",
    "        # Desnormalizar\n",
    "        y_new = scaler_y.inverse_transform(y_new_scaled)\n",
    "        \n",
    "        return y_new[0][0]\n",
    "    \n",
    "    print(\"\\n=== REALIZANDO ANÁLISIS DE SENSIBILIDAD ===\")\n",
    "\n",
    "    # Análisis 1: Impacto del día de la semana\n",
    "    dias = ['Lunes', 'Martes', 'Miércoles', 'Jueves', 'Viernes', 'Sábado', 'Domingo']\n",
    "    ventas_por_dia = []\n",
    "\n",
    "    for i in range(7):\n",
    "        ventas = predict_sales(\n",
    "            dia_semana=i,\n",
    "            festivo=0,\n",
    "            temperatura=20.0,\n",
    "            lluvia=0,\n",
    "            promocion=0,\n",
    "            temporada='Primavera'\n",
    "        )\n",
    "        ventas_por_dia.append(ventas)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(dias, ventas_por_dia)\n",
    "    plt.title('Ventas previstas por día de la semana')\n",
    "    plt.xlabel('Día de la semana')\n",
    "    plt.ylabel('Ventas previstas')\n",
    "    plt.savefig('ventas_por_dia.png')\n",
    "    plt.close()  # Cerrar figura para liberar memoria\n",
    "\n",
    "    print(\"- Análisis de impacto por día de la semana completado\")\n",
    "\n",
    "    # Análisis 2: Impacto de la temperatura\n",
    "    temperaturas = np.arange(0, 41, 2)\n",
    "    ventas_por_temp = []\n",
    "\n",
    "    for temp in temperaturas:\n",
    "        ventas = predict_sales(\n",
    "            dia_semana=5,  # Sábado\n",
    "            festivo=0,\n",
    "            temperatura=temp,\n",
    "            lluvia=0,\n",
    "            promocion=0,\n",
    "            temporada='Verano'\n",
    "        )\n",
    "        ventas_por_temp.append(ventas)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(temperaturas, ventas_por_temp, marker='o')\n",
    "    plt.title('Impacto de la temperatura en las ventas (sábado de verano)')\n",
    "    plt.xlabel('Temperatura (°C)')\n",
    "    plt.ylabel('Ventas previstas')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('ventas_por_temperatura.png')\n",
    "    plt.close()  # Cerrar figura para liberar memoria\n",
    "\n",
    "    print(\"- Análisis de impacto de temperatura completado\")\n",
    "\n",
    "    # Análisis 3: Comparación entre temporadas\n",
    "    temporadas = ['Invierno', 'Primavera', 'Verano', 'Otoño']\n",
    "    ventas_por_temporada = []\n",
    "\n",
    "    for temporada in temporadas:\n",
    "        ventas = predict_sales(\n",
    "            dia_semana=5,  # Sábado\n",
    "            festivo=0,\n",
    "            temperatura=20.0,  # Temperatura moderada en todas las temporadas\n",
    "            lluvia=0,\n",
    "            promocion=0,\n",
    "            temporada=temporada\n",
    "        )\n",
    "        ventas_por_temporada.append(ventas)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(temporadas, ventas_por_temporada)\n",
    "    plt.title('Ventas previstas por temporada (sábado sin promoción)')\n",
    "    plt.xlabel('Temporada')\n",
    "    plt.ylabel('Ventas previstas')\n",
    "    plt.savefig('ventas_por_temporada.png')\n",
    "    plt.close()  # Cerrar figura para liberar memoria\n",
    "\n",
    "    print(\"- Análisis de impacto por temporada completado\")\n",
    "\n",
    "    # Análisis 4: Impacto de promociones por temporada\n",
    "    ventas_con_promo = []\n",
    "    ventas_sin_promo = []\n",
    "\n",
    "    for temporada in temporadas:\n",
    "        # Con promoción\n",
    "        ventas_cp = predict_sales(\n",
    "            dia_semana=5,  # Sábado\n",
    "            festivo=0,\n",
    "            temperatura=20.0,\n",
    "            lluvia=0,\n",
    "            promocion=1,\n",
    "            temporada=temporada\n",
    "        )\n",
    "        ventas_con_promo.append(ventas_cp)\n",
    "       \n",
    "        # Sin promoción\n",
    "        ventas_sp = predict_sales(\n",
    "            dia_semana=5,  # Sábado\n",
    "            festivo=0,\n",
    "            temperatura=20.0,\n",
    "            lluvia=0,\n",
    "            promocion=0,\n",
    "            temporada=temporada\n",
    "        )\n",
    "        ventas_sin_promo.append(ventas_sp)\n",
    "\n",
    "    width = 0.35\n",
    "    x = np.arange(len(temporadas))\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(x - width/2, ventas_sin_promo, width, label='Sin promoción')\n",
    "    plt.bar(x + width/2, ventas_con_promo, width, label='Con promoción')\n",
    "    plt.title('Impacto de promociones por temporada (sábado)')\n",
    "    plt.xlabel('Temporada')\n",
    "    plt.ylabel('Ventas previstas')\n",
    "    plt.xticks(x, temporadas)\n",
    "    plt.legend()\n",
    "    plt.savefig('impacto_promociones.png')\n",
    "    plt.close()  # Cerrar figura para liberar memoria\n",
    "\n",
    "    print(\"- Análisis de impacto de promociones completado\")\n",
    "\n",
    "    # Análisis 5: Impacto de festivos vs no festivos\n",
    "    dias_semana = [0, 5]  # Lunes y Sábado\n",
    "    dias_nombres = ['Lunes', 'Sábado']\n",
    "    ventas_festivo = []\n",
    "    ventas_normal = []\n",
    "\n",
    "    for dia in dias_semana:\n",
    "        # Día festivo\n",
    "        ventas_f = predict_sales(\n",
    "            dia_semana=dia,\n",
    "            festivo=1,\n",
    "            temperatura=20.0,\n",
    "            lluvia=0,\n",
    "            promocion=0,\n",
    "            temporada='Primavera'\n",
    "        )\n",
    "        ventas_festivo.append(ventas_f)\n",
    "       \n",
    "        # Día normal\n",
    "        ventas_n = predict_sales(\n",
    "            dia_semana=dia,\n",
    "            festivo=0,\n",
    "            temperatura=20.0,\n",
    "            lluvia=0,\n",
    "            promocion=0,\n",
    "            temporada='Primavera'\n",
    "        )\n",
    "        ventas_normal.append(ventas_n)\n",
    "\n",
    "    width = 0.35\n",
    "    x = np.arange(len(dias_nombres))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(x - width/2, ventas_normal, width, label='Día normal')\n",
    "    plt.bar(x + width/2, ventas_festivo, width, label='Día festivo')\n",
    "    plt.title('Comparación de ventas en días normales vs festivos')\n",
    "    plt.xlabel('Día')\n",
    "    plt.ylabel('Ventas previstas')\n",
    "    plt.xticks(x, dias_nombres)\n",
    "    plt.legend()\n",
    "    plt.savefig('impacto_festivos.png')\n",
    "    plt.close()  # Cerrar figura para liberar memoria\n",
    "\n",
    "    print(\"- Análisis de impacto de días festivos completado\")\n",
    "\n",
    "    # Análisis 6: Impacto de la lluvia en diferentes temporadas\n",
    "    ventas_con_lluvia = []\n",
    "    ventas_sin_lluvia = []\n",
    "\n",
    "    for temporada in temporadas:\n",
    "        # Con lluvia\n",
    "        ventas_cl = predict_sales(\n",
    "            dia_semana=5,  # Sábado\n",
    "            festivo=0,\n",
    "            temperatura=20.0,\n",
    "            lluvia=1,\n",
    "            promocion=0,\n",
    "            temporada=temporada\n",
    "        )\n",
    "        ventas_con_lluvia.append(ventas_cl)\n",
    "       \n",
    "        # Sin lluvia\n",
    "        ventas_sl = predict_sales(\n",
    "            dia_semana=5,  # Sábado\n",
    "            festivo=0,\n",
    "            temperatura=20.0,\n",
    "            lluvia=0,\n",
    "            promocion=0,\n",
    "            temporada=temporada\n",
    "        )\n",
    "        ventas_sin_lluvia.append(ventas_sl)\n",
    "\n",
    "    width = 0.35\n",
    "    x = np.arange(len(temporadas))\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(x - width/2, ventas_sin_lluvia, width, label='Sin lluvia')\n",
    "    plt.bar(x + width/2, ventas_con_lluvia, width, label='Con lluvia')\n",
    "    plt.title('Impacto de la lluvia por temporada (sábado)')\n",
    "    plt.xlabel('Temporada')\n",
    "    plt.ylabel('Ventas previstas')\n",
    "    plt.xticks(x, temporadas)\n",
    "    plt.legend()\n",
    "    plt.savefig('impacto_lluvia.png')\n",
    "    plt.close()  # Cerrar figura para liberar memoria\n",
    "\n",
    "    print(\"- Análisis de impacto de lluvia completado\")\n",
    "\n",
    "    # Crear un resumen de los hallazgos\n",
    "    print(\"\\n=== RESUMEN DE ANÁLISIS DE SENSIBILIDAD ===\")\n",
    "    print(f\"1. Día con mayores ventas: {dias[np.argmax(ventas_por_dia)]} ({ventas_por_dia[np.argmax(ventas_por_dia)]:.2f})\")\n",
    "    print(f\"2. Temperatura óptima para ventas: {temperaturas[np.argmax(ventas_por_temp)]:.1f}°C ({ventas_por_temp[np.argmax(ventas_por_temp)]:.2f})\")\n",
    "    print(f\"3. Temporada con mayores ventas: {temporadas[np.argmax(ventas_por_temporada)]} ({ventas_por_temporada[np.argmax(ventas_por_temporada)]:.2f})\")\n",
    "\n",
    "    # Calcular el aumento promedio debido a promociones\n",
    "    aumento_promo = [(con - sin) / sin * 100 for con, sin in zip(ventas_con_promo, ventas_sin_promo)]\n",
    "    print(f\"4. Aumento promedio de ventas por promociones: {np.mean(aumento_promo):.2f}%\")\n",
    "\n",
    "    # Calcular el cambio promedio debido a festivos\n",
    "    cambio_festivo = [(festivo - normal) / normal * 100 for festivo, normal in zip(ventas_festivo, ventas_normal)]\n",
    "    print(f\"5. Cambio promedio en ventas en días festivos: {np.mean(cambio_festivo):.2f}%\")\n",
    "\n",
    "    # Calcular el cambio promedio debido a lluvia\n",
    "    cambio_lluvia = [(lluvia - no_lluvia) / no_lluvia * 100 for lluvia, no_lluvia in zip(ventas_con_lluvia, ventas_sin_lluvia)]\n",
    "    print(f\"6. Cambio promedio en ventas por lluvia: {np.mean(cambio_lluvia):.2f}%\")\n",
    "\n",
    "    # Exportar resultados a un archivo CSV\n",
    "    resultados = pd.DataFrame({\n",
    "        'Variable': ['Día de la semana', 'Temperatura', 'Temporada', 'Promoción', 'Festivo', 'Lluvia'],\n",
    "        'Mejor valor': [\n",
    "            dias[np.argmax(ventas_por_dia)],\n",
    "            f\"{temperaturas[np.argmax(ventas_por_temp)]:.1f}°C\",\n",
    "            temporadas[np.argmax(ventas_por_temporada)],\n",
    "            'Con promoción',\n",
    "            'Depende del día',\n",
    "            'Sin lluvia'\n",
    "        ],\n",
    "        'Impacto': [\n",
    "            f\"{(max(ventas_por_dia) - min(ventas_por_dia)) / min(ventas_por_dia) * 100:.2f}%%\",\n",
    "            f\"{(max(ventas_por_temp) - min(ventas_por_temp)) / min(ventas_por_temp) * 100:.2f}%%\",\n",
    "            f\"{(max(ventas_por_temporada) - min(ventas_por_temporada)) / min(ventas_por_temporada) * 100:.2f}%%\",\n",
    "            f\"{np.mean(aumento_promo):.2f}%%\",\n",
    "            f\"{np.mean(cambio_festivo):.2f}%%\",\n",
    "            f\"{np.mean(cambio_lluvia):.2f}%%\"\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    resultados.to_csv('resultados_analisis_sensibilidad.csv', index=False)\n",
    "    print(\"\\nResultados guardados en 'resultados_analisis_sensibilidad.csv'\")\n",
    "\n",
    "    print(\"\\n=== PROCESO COMPLETO FINALIZADO CON ÉXITO ===\")\n",
    "    print(\"Archivos generados:\")\n",
    "    print(\"- ventas_tienda_diarias.csv (Dataset)\")\n",
    "    print(\"- modelo_ventas_tienda.h5 (Modelo entrenado)\")\n",
    "    print(\"- ventas_por_dia.png (Gráfica)\")  \n",
    "    print(\"- ventas_por_temperatura.png (Gráfica)\")\n",
    "    print(\"- ventas_por_temporada.png (Gráfica)\")\n",
    "    print(\"- impacto_promociones.png (Gráfica)\")\n",
    "    print(\"- impacto_festivos.png (Gráfica)\")\n",
    "    print(\"- impacto_lluvia.png (Gráfica)\")\n",
    "    print(\"- resultados_analisis_sensibilidad.csv (Resumen de resultados)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Módulo 2: Clasificación de Imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modulo_clasificacion_imagenes():\n",
    "    print(\"=== CARGANDO DATASET MNIST ===\")\n",
    "    \n",
    "    # Cargar el dataset MNIST\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    \n",
    "    # Normalizar los datos\n",
    "    X_train = X_train.astype('float32') / 255\n",
    "    X_test = X_test.astype('float32') / 255\n",
    "    \n",
    "    # Reshape para CNN\n",
    "    X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "    \n",
    "    print(f\"Tamaño del conjunto de entrenamiento: {X_train.shape[0]} imágenes\")\n",
    "    print(f\"Tamaño del conjunto de prueba: {X_test.shape[0]} imágenes\")\n",
    "    print(f\"Forma de cada imagen: {X_train.shape[1:]} píxeles\")\n",
    "    \n",
    "    # Visualizar algunas imágenes de muestra\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i in range(10):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.imshow(X_train[i].reshape(28, 28), cmap='gray')\n",
    "        plt.title(f'Dígito: {y_train[i]}')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('mnist_muestras.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"- Muestra de imágenes guardada como 'mnist_muestras.png'\")\n",
    "    \n",
    "    print(\"\\n=== CONSTRUYENDO Y ENTRENANDO CNN PARA MNIST ===\")\n",
    "    \n",
    "    # Construir modelo CNN para MNIST\n",
    "    model_cnn = Sequential([\n",
    "        Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(10, activation='softmax')  # 10 clases (dígitos 0-9)\n",
    "    ])\n",
    "    \n",
    "    # Compilar el modelo\n",
    "    model_cnn.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Entrenar el modelo (con menos épocas para ser más rápido)\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    history_cnn = model_cnn.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=128,\n",
    "        epochs=5,  # Pocas épocas para ser rápido\n",
    "        validation_split=0.1,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluar el modelo\n",
    "    test_loss, test_acc = model_cnn.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Precisión en el conjunto de prueba: {test_acc*100:.2f}%\")\n",
    "    \n",
    "    # Guardar el modelo\n",
    "    model_cnn.save('modelo_mnist.h5')\n",
    "    print(\"Modelo guardado como 'modelo_mnist.h5'\")\n",
    "    \n",
    "    # Visualizar algunas predicciones\n",
    "    predictions = model_cnn.predict(X_test[:10])\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(10):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.imshow(X_test[i].reshape(28, 28), cmap='gray')\n",
    "        color = 'green' if predicted_classes[i] == y_test[i] else 'red'\n",
    "        plt.title(f'Pred: {predicted_classes[i]}, Real: {y_test[i]}', color=color)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('mnist_predicciones.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"- Predicciones guardadas como 'mnist_predicciones.png'\")\n",
    "    \n",
    "    # Visualizar matriz de confusión\n",
    "    y_pred = model_cnn.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    confusion_mtx = tf.math.confusion_matrix(y_test, y_pred_classes)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(confusion_mtx, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicción')\n",
    "    plt.ylabel('Real')\n",
    "    plt.title('Matriz de Confusión')\n",
    "    plt.savefig('mnist_confusion_matrix.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"- Matriz de confusión guardada como 'mnist_confusion_matrix.png'\")\n",
    "    \n",
    "    print(\"\\n=== CLASIFICADOR DE IMÁGENES MNIST FINALIZADO CON ÉXITO ===\")\n",
    "    print(\"Archivos generados:\")\n",
    "    print(\"- mnist_muestras.png (Muestra de imágenes)\")\n",
    "    print(\"- modelo_mnist.h5 (Modelo CNN entrenado)\")\n",
    "    print(\"- mnist_predicciones.png (Visualización de predicciones)\")\n",
    "    print(\"- mnist_confusion_matrix.png (Matriz de confusión)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Módulo 3: Análisis de Sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modulo_analisis_sentimientos():\n",
    "    print(\"=== GENERANDO DATASET DE ANÁLISIS DE SENTIMIENTOS ===\")\n",
    "    \n",
    "    # Generar un pequeño dataset de reseñas de ejemplo\n",
    "    reseñas = [\n",
    "        \"Este producto es excelente, estoy muy contento con mi compra.\",\n",
    "        \"No me gustó nada, es de pésima calidad y no funciona bien.\",\n",
    "        \"Buena relación calidad-precio, recomendable.\",\n",
    "        \"Decepcionante, no cumple con lo que promete en el anuncio.\",\n",
    "        \"Increíble producto, supera todas mis expectativas.\",\n",
    "        \"Terrible servicio al cliente, nunca más compraré aquí.\",\n",
    "        \"La entrega fue rápida y el producto llegó en perfectas condiciones.\",\n",
    "        \"Pésima experiencia de compra, el producto vino dañado.\",\n",
    "        \"Me encanta, funciona muy bien y es fácil de usar.\",\n",
    "        \"No lo recomiendo, se rompió a los pocos días de usarlo.\",\n",
    "        \"Buena calidad de construcción, resistente y duradero.\",\n",
    "        \"Demasiado caro para lo que ofrece, hay mejores opciones.\",\n",
    "        \"Excelente atención al cliente, resolvieron mi problema rápidamente.\",\n",
    "        \"La aplicación es intuitiva y funciona sin problemas.\",\n",
    "        \"Inestable y lleno de errores, no puedo utilizarlo correctamente.\",\n",
    "        \"Gran producto, vale cada centavo que pagué por él.\",\n",
    "        \"No puedo estar más feliz con esta compra, totalmente recomendable.\",\n",
    "        \"Decepción total, nada que ver con lo que esperaba.\",\n",
    "        \"Perfecto para mis necesidades, justo lo que buscaba.\",\n",
    "        \"Mala experiencia, no volveré a confiar en esta marca.\"\n",
    "    ]\n",
    "    \n",
    "    # Asignar etiquetas manualmente (0: negativo, 1: positivo)\n",
    "    sentimientos = [\n",
    "        1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
    "        1, 0, 1, 1, 0, 1, 1, 0, 1, 0\n",
    "    ]\n",
    "    \n",
    "    # Crear DataFrame\n",
    "    df_sentimientos = pd.DataFrame({\n",
    "        'reseña': reseñas,\n",
    "        'sentimiento': sentimientos\n",
    "    })\n",
    "    \n",
    "    # Guardar a CSV\n",
    "    df_sentimientos.to_csv('dataset_sentimientos.csv', index=False)\n",
    "    \n",
    "    print(f\"Dataset creado con {len(df_sentimientos)} reseñas\")\n",
    "    print(\"- Guardado como 'dataset_sentimientos.csv'\")\n",
    "    \n",
    "    # Mostrar distribución de sentimientos\n",
    "    count_sentimientos = df_sentimientos['sentimiento'].value_counts()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(['Negativo', 'Positivo'], [count_sentimientos[0], count_sentimientos[1]])\n",
    "    plt.title('Distribución de Sentimientos en el Dataset')\n",
    "    plt.savefig('distribucion_sentimientos.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\n=== PREPROCESANDO TEXTO PARA ANÁLISIS DE SENTIMIENTOS ===\")\n",
    "    \n",
    "    # Tokenización y padding\n",
    "    max_palabras = 1000\n",
    "    max_longitud = 100\n",
    "    \n",
    "    tokenizer = Tokenizer(num_words=max_palabras, oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(df_sentimientos['reseña'])\n",
    "    \n",
    "    secuencias = tokenizer.texts_to_sequences(df_sentimientos['reseña'])\n",
    "    secuencias_padded = pad_sequences(secuencias, maxlen=max_longitud, padding='post')\n",
    "    \n",
    "    # Dividir en conjuntos de entrenamiento y prueba\n",
    "    X = secuencias_padded\n",
    "    y = np.array(df_sentimientos['sentimiento'])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(f\"Tamaño del vocabulario: {len(tokenizer.word_index) + 1}\")\n",
    "    print(f\"Longitud máxima de secuencia: {max_longitud}\")\n",
    "    \n",
    "    print(\"\\n=== CONSTRUYENDO MODELO DE ANÁLISIS DE SENTIMIENTOS ===\")\n",
    "    \n",
    "    # Construir modelo\n",
    "    model_sentimiento = Sequential([\n",
    "        Embedding(max_palabras, 16, input_length=max_longitud),\n",
    "        Dropout(0.2),\n",
    "        Flatten(),\n",
    "        Dense(24, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compilar modelo\n",
    "    model_sentimiento.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Entrenar modelo\n",
    "    history_sentimiento = model_sentimiento.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=10,\n",
    "        validation_split=0.2,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluar en conjunto de prueba\n",
    "    test_loss, test_acc = model_sentimiento.evaluate(X_test, y_test)\n",
    "    print(f\"\\nPrecisión en conjunto de prueba: {test_acc*100:.2f}%\")\n",
    "    \n",
    "    # Guardar modelo\n",
    "    model_sentimiento.save('modelo_sentimientos.h5')\n",
    "    print(\"Modelo guardado como 'modelo_sentimientos.h5'\")\n",
    "    \n",
    "    # Visualizar curva de aprendizaje\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history_sentimiento.history['accuracy'], label='train')\n",
    "    plt.plot(history_sentimiento.history['val_accuracy'], label='validation')\n",
    "    plt.title('Curva de Aprendizaje - Precisión')\n",
    "    plt.xlabel('Épocas')\n",
    "    plt.ylabel('Precisión')\n",
    "    plt.legend()\n",
    "    plt.savefig('curva_aprendizaje_sentimientos.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Hacer predicciones con nuevas reseñas\n",
    "    nuevas_reseñas = [\n",
    "        \"Este producto es una maravilla, lo recomiendo totalmente\",\n",
    "        \"Terrible experiencia, no volvería a comprar este producto\"\n",
    "    ]\n",
    "    \n",
    "    nuevas_secuencias = tokenizer.texts_to_sequences(nuevas_reseñas)\n",
    "    nuevas_padded = pad_sequences(nuevas_secuencias, maxlen=max_longitud, padding='post')\n",
    "    \n",
    "    predicciones = model_sentimiento.predict(nuevas_padded)\n",
    "    \n",
    "    print(\"\\n=== PREDICCIONES CON NUEVAS RESEÑAS ===\")\n",
    "    for i, reseña in enumerate(nuevas_reseñas):\n",
    "        sentimiento = \"Positivo\" if predicciones[i][0] > 0.5 else \"Negativo\"\n",
    "        confianza = predicciones[i][0] if predicciones[i][0] > 0.5 else 1 - predicciones[i][0]\n",
    "        print(f\"Reseña: '{reseña}'\")\n",
    "        print(f\"Predicción: {sentimiento} (confianza: {confianza*100:.2f}%)\\n\")\n",
    "    \n",
    "    print(\"\\n=== ANÁLISIS DE SENTIMIENTOS FINALIZADO CON ÉXITO ===\")\n",
    "    print(\"Archivos generados:\")\n",
    "    print(\"- dataset_sentimientos.csv (Dataset)\")\n",
    "    print(\"- distribucion_sentimientos.png (Gráfica)\")\n",
    "    print(\"- modelo_sentimientos.h5 (Modelo entrenado)\")\n",
    "    print(\"- curva_aprendizaje_sentimientos.png (Gráfica)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Módulo 4: Generación de Contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modulo_generacion_contenido():\n",
    "    print(\"=== IMPLEMENTANDO GENERADOR DE TEXTO SIMPLE ===\")\n",
    "    \n",
    "    # Texto de ejemplo (fragmento de Don Quijote)\n",
    "    texto_ejemplo = \"\"\"\n",
    "    En un lugar de la Mancha, de cuyo nombre no quiero acordarme, no ha mucho tiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua, rocín flaco y galgo corredor. Una olla de algo más vaca que carnero, salpicón las más noches, duelos y quebrantos los sábados, lantejas los viernes, algún palomino de añadidura los domingos, consumían las tres partes de su hacienda. El resto della concluían sayo de velarte, calzas de velludo para las fiestas, con sus pantuflos de lo mesmo, y los días de entresemana se honraba con su vellorí de lo más fino. Tenía en su casa una ama que pasaba de los cuarenta, y una sobrina que no llegaba a los veinte, y un mozo de campo y plaza, que así ensillaba el rocín como tomaba la podadera. Frisaba la edad de nuestro hidalgo con los cincuenta años; era de complexión recia, seco de carnes, enjuto de rostro, gran madrugador y amigo de la caza. Quieren decir que tenía el sobrenombre de Quijada, o Quesada, que en esto hay alguna diferencia en los autores que deste caso escriben; aunque por conjeturas verosímiles se deja entender que se llamaba Quijana. Pero esto importa poco a nuestro cuento: basta que en la narración dél no se salga un punto de la verdad.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Preprocesar texto\n",
    "    texto_ejemplo = texto_ejemplo.lower().strip()\n",
    "    \n",
    "    # Crear secuencias de caracteres\n",
    "    longitud_secuencia = 50\n",
    "    paso = 3\n",
    "    \n",
    "    secuencias_texto = []\n",
    "    siguiente_char = []\n",
    "    \n",
    "    for i in range(0, len(texto_ejemplo) - longitud_secuencia, paso):\n",
    "        secuencias_texto.append(texto_ejemplo[i:i + longitud_secuencia])\n",
    "        siguiente_char.append(texto_ejemplo[i + longitud_secuencia])\n",
    "    \n",
    "    print(f\"Número de secuencias: {len(secuencias_texto)}\")\n",
    "    \n",
    "    # Crear mapeo de caracteres a índices\n",
    "    chars = sorted(list(set(texto_ejemplo)))\n",
    "    char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "    indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "    \n",
    "    print(f\"Número de caracteres únicos: {len(chars)}\")\n",
    "    \n",
    "    # Vectorizar secuencias\n",
    "    X = np.zeros((len(secuencias_texto), longitud_secuencia, len(chars)), dtype=np.bool_)\n",
    "    y = np.zeros((len(secuencias_texto), len(chars)), dtype=np.bool_)\n",
    "    \n",
    "    for i, secuencia in enumerate(secuencias_texto):\n",
    "        for t, char in enumerate(secuencia):\n",
    "            X[i, t, char_indices[char]] = 1\n",
    "        y[i, char_indices[siguiente_char[i]]] = 1\n",
    "    \n",
    "    print(\"\\n=== CONSTRUYENDO MODELO GENERADOR DE TEXTO ===\")\n",
    "    \n",
    "    # Construir modelo LSTM simple\n",
    "    model_texto = Sequential([\n",
    "        LSTM(128, input_shape=(longitud_secuencia, len(chars))),\n",
    "        Dense(len(chars), activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compilar modelo\n",
    "    model_texto.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer='adam'\n",
    "    )\n",
    "    \n",
    "    # Entrenar modelo (pocas épocas para ser rápido)\n",
    "    model_texto.fit(X, y, batch_size=128, epochs=5)\n",
    "    \n",
    "    # Guardar modelo\n",
    "    model_texto.save('modelo_generador_texto.h5')\n",
    "    print(\"Modelo guardado como 'modelo_generador_texto.h5'\")\n",
    "    \n",
    "    # Función para generar texto\n",
    "    def generar_texto(modelo, semilla, longitud_generada=200):\n",
    "        texto_generado = semilla\n",
    "        \n",
    "        for i in range(longitud_generada):\n",
    "            x_pred = np.zeros((1, longitud_secuencia, len(chars)))\n",
    "            for t, char in enumerate(texto_generado[-longitud_secuencia:]):\n",
    "                if char in char_indices:\n",
    "                    x_pred[0, t, char_indices[char]] = 1\n",
    "            \n",
    "            probas = modelo.predict(x_pred, verbose=0)[0]\n",
    "            siguiente_indice = np.random.choice(len(chars), p=probas)\n",
    "            siguiente_caracter = indices_char[siguiente_indice]\n",
    "            \n",
    "            texto_generado += siguiente_caracter\n",
    "        \n",
    "        return texto_generado\n",
    "    \n",
    "    # Generar ejemplos de texto\n",
    "    semillas = [\n",
    "        \"en un lugar de la mancha\",\n",
    "        \"caballero de noble figura\",\n",
    "        \"entre molinos y gigantes\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n=== EJEMPLOS DE TEXTO GENERADO ===\")\n",
    "    for semilla in semillas:\n",
    "        texto_generado = generar_texto(model_texto, semilla)\n",
    "        print(f\"\\nSemilla: '{semilla}'\")\n",
    "        print(f\"Texto generado:\\n{texto_generado}\")\n",
    "        \n",
    "        # Guardar texto generado en archivo\n",
    "        with open(f\"texto_generado_{semilla[:10].replace(' ', '_')}.txt\", 'w', encoding='utf-8') as f:\n",
    "            f.write(texto_generado)\n",
    "    \n",
    "    print(\"\\n=== GENERACIÓN DE IMÁGENES SIMPLES ===\")\n",
    "    \n",
    "    # Crear imágenes abstractas simples usando patrones matemáticos\n",
    "    def generar_imagen_fractal(tamaño=400, complejidad=0.7, colorido=0.5):\n",
    "        # Crear malla de coordenadas\n",
    "        x = np.linspace(-2, 2, tamaño)\n",
    "        y = np.linspace(-2, 2, tamaño)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        Z = X + 1j * Y\n",
    "        \n",
    "        # Inicializar imagen\n",
    "        imagen = np.zeros((tamaño, tamaño, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Generar patrón fractal simple\n",
    "        c = complex(-0.8, 0.156)\n",
    "        \n",
    "        for i in range(tamaño):\n",
    "            for j in range(tamaño):\n",
    "                z = Z[i][j]\n",
    "                iteraciones = 0\n",
    "                max_iter = 20 + int(complejidad * 100)\n",
    "                \n",
    "                while abs(z) < 10 and iteraciones < max_iter:\n",
    "                    z = z**2 + c\n",
    "                    iteraciones += 1\n",
    "                if iteraciones < max_iter:\n",
    "                    ratio = iteraciones / max_iter\n",
    "                    # Asignar colores según iteraciones\n",
    "                    imagen[i, j, 0] = int(255 * abs(np.sin(ratio * 3.14 * (1 + colorido))))  # R\n",
    "                    imagen[i, j, 1] = int(255 * abs(np.sin(ratio * 6.28 * colorido)))  # G\n",
    "                    imagen[i, j, 2] = int(255 * abs(np.cos(ratio * 3.14 * (1 - colorido))))  # B\n",
    "       \n",
    "        return imagen\n",
    "    \n",
    "    # Generar varias imágenes con diferentes parámetros\n",
    "    for i, (complejidad, colorido) in enumerate([(0.5, 0.3), (0.7, 0.5), (0.9, 0.7)]):\n",
    "        nombre_imagen = f\"imagen_generada_{i+1}.png\"\n",
    "        \n",
    "        # Generar imagen\n",
    "        imagen = generar_imagen_fractal(tamaño=400, complejidad=complejidad, colorido=colorido)\n",
    "        \n",
    "        # Guardar imagen\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(imagen)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Imagen generada (c:{complejidad}, col:{colorido})\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(nombre_imagen)\n",
    "        plt.close()\n",
    "        print(f\"- Imagen guardada como '{nombre_imagen}'\")\n",
    "    \n",
    "    print(\"\\n=== GENERACIÓN DE CONTENIDO FINALIZADA CON ÉXITO ===\")\n",
    "    print(\"Archivos generados:\")\n",
    "    print(\"- modelo_generador_texto.h5 (Modelo generador de texto)\")\n",
    "    print(\"- texto_generado_*.txt (Textos generados)\")\n",
    "    print(\"- imagen_generada_*.png (Imágenes generadas)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SISTEMA DE ML MULTI-MÓDULO ===\n",
      "Seleccione el módulo a ejecutar:\n",
      "1. Predicción de Series Temporales (Ventas)\n",
      "2. Clasificación de Imágenes (MNIST)\n",
      "3. Análisis de Sentimientos\n",
      "4. Generación de Contenido\n",
      "\n",
      "=== EJECUTANDO MÓDULO 4: GENERACIÓN DE CONTENIDO ===\n",
      "=== IMPLEMENTANDO GENERADOR DE TEXTO SIMPLE ===\n",
      "Número de secuencias: 385\n",
      "Número de caracteres únicos: 35\n",
      "\n",
      "=== CONSTRUYENDO MODELO GENERADOR DE TEXTO ===\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Javier\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 3.5448\n",
      "Epoch 2/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.4957\n",
      "Epoch 3/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.4206\n",
      "Epoch 4/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 3.1121\n",
      "Epoch 5/5\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3.0176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado como 'modelo_generador_texto.h5'\n",
      "\n",
      "=== EJEMPLOS DE TEXTO GENERADO ===\n",
      "\n",
      "Semilla: 'en un lugar de la mancha'\n",
      "Texto generado:\n",
      "en un lugar de la mancha ood haooe;ñlo l nxe  e  olas vasooéaxeecn onoolaa  dayodo lomgórooo e lnaxsonr o oaru lélqoea oenmoréhooov  pjos slnot looo adoa v úooa ooo oooooo l gh d ov vna moo  fa;aotgsbl;oéodo snloo oaoooon oa\n",
      "\n",
      "Semilla: 'caballero de noble figura'\n",
      "Texto generado:\n",
      "caballero de noble figurana o ob n ao o aoa eaoaosjsex omeoo  ooyovoa oo dvmil ee ohoo.olr.ooa ooaoeo sad  nao ec  hlgno lxnoaooná  oo a aonde aozo soolea aalol vuoónx e;  ooo ooeoacsalso   ol vnalo aoloj  l  oéooax vóoéoaio \n",
      "\n",
      "Semilla: 'entre molinos y gigantes'\n",
      "Texto generado:\n",
      "entre molinos y gigantesoé osuxnéo loaoo oon  dtao;boo i lo aetó oeeotvodoaodoa t n;   ravoionoadsusioln o cp   umhoocooo rnah  o hn zaaa; oy.oooiaaoo esoéoeoo no oov aoaoo nnetoooltoopao ddépoooume ooe o ozjaoooy noq ooe r \n",
      "\n",
      "=== GENERACIÓN DE IMÁGENES SIMPLES ===\n",
      "- Imagen guardada como 'imagen_generada_1.png'\n",
      "- Imagen guardada como 'imagen_generada_2.png'\n",
      "- Imagen guardada como 'imagen_generada_3.png'\n",
      "\n",
      "=== GENERACIÓN DE CONTENIDO FINALIZADA CON ÉXITO ===\n",
      "Archivos generados:\n",
      "- modelo_generador_texto.h5 (Modelo generador de texto)\n",
      "- texto_generado_*.txt (Textos generados)\n",
      "- imagen_generada_*.png (Imágenes generadas)\n",
      "\n",
      "=== PROGRAMA FINALIZADO ===\n"
     ]
    }
   ],
   "source": [
    "# Código principal que permite elegir el módulo a ejecutar\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== SISTEMA DE ML MULTI-MÓDULO ===\")\n",
    "    print(\"Seleccione el módulo a ejecutar:\")\n",
    "    print(\"1. Predicción de Series Temporales (Ventas)\")\n",
    "    print(\"2. Clasificación de Imágenes (MNIST)\")\n",
    "    print(\"3. Análisis de Sentimientos\")\n",
    "    print(\"4. Generación de Contenido\")\n",
    "    \n",
    "    try:\n",
    "        opcion = int(input(\"\\nIngrese el número del módulo (1-4): \"))\n",
    "        ejecutar_modulo(opcion)\n",
    "    except ValueError:\n",
    "        print(\"Por favor ingrese un número válido (1-4)\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nEjecución interrumpida por el usuario\")\n",
    "    finally:\n",
    "        print(\"\\n=== PROGRAMA FINALIZADO ===\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
